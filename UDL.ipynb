{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在提取帧...\n",
      "总帧数: 1476\n",
      "从第 3 帧开始，间隔 60 帧\n",
      "预计处理帧数: 24\n",
      "提取帧进度: 25/24\n",
      "帧提取完成\n"
     ]
    }
   ],
   "source": [
    "def create_folders():\n",
    "    \"\"\"创建必要的文件夹结构\"\"\"\n",
    "    folders = [\n",
    "        'temp_frames',\n",
    "        'output'\n",
    "    ]\n",
    "    \n",
    "    for folder in folders:\n",
    "        Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def extract_frames(video_path, start_frame, frame_interval):\n",
    "    \"\"\"\n",
    "    从指定帧开始提取帧\n",
    "    Args:\n",
    "        video_path: 视频路径\n",
    "        start_frame: 开始帧的索引\n",
    "        frame_interval: 帧间隔\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"无法打开视频文件: {video_path}\")\n",
    "    \n",
    "    try:\n",
    "        frame_count = 0\n",
    "        saved_count = 0\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        print(f\"总帧数: {total_frames}\")\n",
    "        print(f\"从第 {start_frame} 帧开始，间隔 {frame_interval} 帧\")\n",
    "        print(f\"预计处理帧数: {(total_frames - start_frame) // frame_interval}\")\n",
    "        \n",
    "        # 跳到指定的开始帧\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            if frame_count % frame_interval == 0:\n",
    "                cv2.imwrite(f'temp_frames/frame_{saved_count}.jpg', frame)\n",
    "                print(f\"\\r提取帧进度: {saved_count + 1}/{(total_frames - start_frame) // frame_interval}\", end=\"\", flush=True)\n",
    "                saved_count += 1\n",
    "                \n",
    "            frame_count += 1\n",
    "            del frame\n",
    "            gc.collect()\n",
    "        \n",
    "        print(\"\\n帧提取完成\")\n",
    "        return saved_count\n",
    "        \n",
    "    finally:\n",
    "        cap.release()\n",
    "        gc.collect()\n",
    "        \n",
    "def cleanup():\n",
    "    \"\"\"清理临时文件\"\"\"\n",
    "    try:\n",
    "        shutil.rmtree('temp_frames', ignore_errors=True)\n",
    "    except Exception as e:\n",
    "        print(f\"清理临时文件时出错: {str(e)}\")       \n",
    "\n",
    "# 创建必要的文件夹\n",
    "create_folders()\n",
    "Path('checkpoints').mkdir(exist_ok=True)\n",
    "\n",
    "video_path = \"video/7.mp4\"\n",
    "start_frame = 3\n",
    "frame_interval = 60\n",
    "# 提取帧\n",
    "print(\"正在提取帧...\")\n",
    "total_frames = extract_frames(video_path, start_frame, frame_interval)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, padding=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 保持特征图的空间信息\n",
    "        f1 = self.relu(self.bn1(self.conv1(x)))\n",
    "        p1 = self.pool(f1)\n",
    "        \n",
    "        f2 = self.relu(self.bn2(self.conv2(p1)))\n",
    "        p2 = self.pool(f2)\n",
    "        \n",
    "        f3 = self.relu(self.bn3(self.conv3(p2)))\n",
    "        \n",
    "        return [f1, f2, f3]\n",
    "\n",
    "class CorrelationLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, feat1, feat2):\n",
    "        b, c, h, w = feat1.size()\n",
    "        # 计算特征相关性\n",
    "        feat1_flat = feat1.view(b, c, -1)\n",
    "        feat2_flat = feat2.view(b, c, -1)\n",
    "        \n",
    "        correlation = torch.bmm(feat1_flat.permute(0,2,1), feat2_flat)\n",
    "        correlation = correlation.view(b, h*w, h, w)\n",
    "        return F.softmax(correlation, dim=1)\n",
    "\n",
    "class StitchingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.correlation = CorrelationLayer()\n",
    "        \n",
    "        # 自适应特征融合\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # 融合权重预测\n",
    "        self.blend_weights = nn.Conv2d(64, 1, 1)\n",
    "        \n",
    "    def forward(self, img1, img2):\n",
    "        # 提取多尺度特征\n",
    "        feats1 = self.feature_extractor(img1)\n",
    "        feats2 = self.feature_extractor(img2)\n",
    "        \n",
    "        # 计算特征相关性\n",
    "        correlations = []\n",
    "        for f1, f2 in zip(feats1, feats2):\n",
    "            corr = self.correlation(f1, f2)\n",
    "            correlations.append(corr)\n",
    "        \n",
    "        # 特征融合\n",
    "        fusion_feats = torch.cat([feats1[-1], feats2[-1]], dim=1)\n",
    "        fused = self.fusion(fusion_feats)\n",
    "        \n",
    "        # 预测融合权重\n",
    "        weights = torch.sigmoid(self.blend_weights(fused))\n",
    "        \n",
    "        # 上采样权重到原始图像大小\n",
    "        weights = F.interpolate(weights, size=img1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        \n",
    "        # 生成最终结果\n",
    "        result = weights * img1 + (1 - weights) * img2\n",
    "        \n",
    "        return result, weights, correlations\n",
    "\n",
    "class StitchingLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, result, img1, img2, weights, correlations):\n",
    "        # 重建损失\n",
    "        reconstruct_loss = self.l1_loss(result, img2)\n",
    "        \n",
    "        # 相关性一致性损失\n",
    "        correlation_loss = sum(self.mse_loss(corr, torch.ones_like(corr)/corr.shape[1]) \n",
    "                             for corr in correlations)\n",
    "        \n",
    "        # 平滑度损失\n",
    "        smoothness_loss = self.l1_loss(weights[:,:,1:,:], weights[:,:,:-1,:]) + \\\n",
    "                         self.l1_loss(weights[:,:,:,1:], weights[:,:,:,:-1])\n",
    "        \n",
    "        total_loss = reconstruct_loss + 0.1 * correlation_loss + 0.01 * smoothness_loss\n",
    "        return total_loss\n",
    "\n",
    "def train_step(model, optimizer, img1, img2):\n",
    "    \"\"\"单步训练函数\"\"\"\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 前向传播\n",
    "    result, weights, correlations = model(img1, img2)\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = StitchingLoss()(result, img1, img2, weights, correlations)\n",
    "    \n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FramePairsDataset(Dataset):\n",
    "    def __init__(self, frames_dir, size=(128, 128)):\n",
    "        self.frames_dir = Path(frames_dir)\n",
    "        self.frame_pairs = self._get_frame_pairs()\n",
    "        self.size = size\n",
    "        \n",
    "        # 使用PIL Image进行转换\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x[:3] if x.size(0) > 3 else x),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            frame1_path, frame2_path = self.frame_pairs[idx]\n",
    "            \n",
    "            # 读取并预处理图像\n",
    "            frame1 = self._safe_read_image(frame1_path)\n",
    "            frame2 = self._safe_read_image(frame2_path)\n",
    "            \n",
    "            # 转换为张量\n",
    "            frame1_tensor = self.transform(frame1)\n",
    "            frame2_tensor = self.transform(frame2)\n",
    "            \n",
    "            # 打印张量形状用于调试\n",
    "            print(f\"Tensor shapes - frame1: {frame1_tensor.shape}, frame2: {frame2_tensor.shape}\")\n",
    "            \n",
    "            return frame1_tensor, frame2_tensor\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {idx}: {str(e)}\")\n",
    "            # 返回全零张量\n",
    "            return torch.zeros(3, *self.size), torch.zeros(3, *self.size)\n",
    "        \n",
    "    def _get_frame_pairs(self):\n",
    "        \"\"\"获取相邻帧对，确保文件存在且可读\"\"\"\n",
    "        frames = []\n",
    "        for frame in sorted(list(self.frames_dir.glob('frame_*.jpg'))):\n",
    "            if frame.exists() and frame.stat().st_size > 0:\n",
    "                frames.append(frame)\n",
    "                \n",
    "        if not frames:\n",
    "            raise RuntimeError(f\"No valid frames found in {self.frames_dir}\")\n",
    "            \n",
    "        return [(frames[i], frames[i+1]) for i in range(len(frames)-1)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.frame_pairs)\n",
    "    \n",
    "    def _safe_read_image(self, path):\n",
    "        \"\"\"安全地读取和处理图像，确保输出为3通道RGB图像\"\"\"\n",
    "        try:\n",
    "            # 使用IMREAD_COLOR确保读取为3通道\n",
    "            img = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
    "            if img is None:\n",
    "                raise ValueError(f\"Failed to read image: {path}\")\n",
    "            \n",
    "            # 调整图像大小以确保一致性\n",
    "            img = cv2.resize(img, self.size, interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            # 确保是3通道RGB图像\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # 确保图像为uint8类型\n",
    "            img = img.astype(np.uint8)\n",
    "            \n",
    "            # 打印图像形状和类型信息（用于调试）\n",
    "            # print(f\"Image shape: {img.shape}, dtype: {img.dtype}\")\n",
    "            \n",
    "            return img\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading image {path}: {str(e)}\")\n",
    "            # 返回一个空白图像而不是失败\n",
    "            return np.zeros((*self.size, 3), dtype=np.uint8)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            frame1_path, frame2_path = self.frame_pairs[idx]\n",
    "            \n",
    "            # 安全读取图像\n",
    "            frame1 = self._safe_read_image(frame1_path)\n",
    "            frame2 = self._safe_read_image(frame2_path)\n",
    "            \n",
    "            # 应用变换\n",
    "            if self.transform:\n",
    "                try:\n",
    "                    frame1 = self.transform(frame1)\n",
    "                    frame2 = self.transform(frame2)\n",
    "                except Exception as e:\n",
    "                    print(f\"Transform error for index {idx}: {str(e)}\")\n",
    "                    # 返回零张量而不是失败\n",
    "                    frame1 = torch.zeros((3, *self.size))\n",
    "                    frame2 = torch.zeros((3, *self.size))\n",
    "            \n",
    "            return frame1, frame2\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {idx}: {str(e)}\")\n",
    "            # 返回零张量而不是失败\n",
    "            return torch.zeros((3, *self.size)), torch.zeros((3, *self.size))\n",
    "\n",
    "def train_model(model, train_loader, num_epochs, device):\n",
    "    \"\"\"训练模型\"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = StitchingLoss()\n",
    "\n",
    "    # 用于提前停止的变量\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    avg_loss = float('inf')  # 初始化avg_loss\n",
    "\n",
    "    # 创建进度条\n",
    "    epoch_pbar = tqdm(total=num_epochs, desc=\"Training Progress\")\n",
    "\n",
    "    try:\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            batch_count = 0\n",
    "\n",
    "            # 添加梯度累积\n",
    "            accumulation_steps = 4  # 累积4次更新一次\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 创建每个epoch的batch进度条\n",
    "            batch_pbar = tqdm(total=len(train_loader),\n",
    "                            desc=f\"Epoch {epoch+1}/{num_epochs}\",\n",
    "                            leave=False)\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            for batch_idx, (img1, img2) in enumerate(train_loader):\n",
    "                try:\n",
    "                    img1, img2 = img1.to(device), img2.to(device)\n",
    "\n",
    "                    # 清除GPU缓存\n",
    "                    if batch_idx % 5 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "\n",
    "                    # 前向传播和损失计算\n",
    "                    result, weights, correlations = model(img1, img2)\n",
    "                    loss = criterion(result, img1, img2, weights, correlations)\n",
    "                    loss = loss / accumulation_steps  # 缩放loss\n",
    "                    loss.backward()\n",
    "\n",
    "                    # 累积梯度\n",
    "                    if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "                    batch_count += 1\n",
    "\n",
    "                    # 更新batch进度条\n",
    "                    batch_pbar.update(1)\n",
    "                    batch_pbar.set_postfix({\n",
    "                        'loss': f'{loss.item():.4f}',\n",
    "                        'avg_loss': f'{total_loss/batch_count:.4f}'\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"\\\\nError in batch {batch_idx}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "            batch_pbar.close()\n",
    "\n",
    "            # 计算平均损失\n",
    "            avg_loss = total_loss / batch_count if batch_count > 0 else float('inf')\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "            # 更新epoch进度条\n",
    "            epoch_pbar.update(1)\n",
    "            epoch_pbar.set_postfix({\n",
    "                'avg_loss': f'{avg_loss:.4f}',\n",
    "                'time': f'{epoch_time:.1f}s'\n",
    "            })\n",
    "\n",
    "            # 提前停止检查\n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                patience_counter = 0\n",
    "                # 保存最佳模型\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': avg_loss,\n",
    "                }, 'checkpoints/best_model.pt')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # 定期保存检查点\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': avg_loss,\n",
    "                }, f'checkpoints/model_epoch_{epoch+1}.pt')\n",
    "\n",
    "            # 如果连续多个epoch没有改善，提前停止\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\\\nEarly stopping after {epoch+1} epochs\")\n",
    "                break\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\\\nTraining interrupted by user\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\\\nTraining error: {str(e)}\")\n",
    "    finally:\n",
    "        epoch_pbar.close()\n",
    "        # 确保最后一个模型状态被保存\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss,\n",
    "        }, 'checkpoints/final_model.pt')\n",
    "\n",
    "\n",
    "def stitch_with_model(model, img1, img2, device):\n",
    "    \"\"\"使用训练好的模型进行图像拼接\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        img1 = img1.unsqueeze(0).to(device)\n",
    "        img2 = img2.unsqueeze(0).to(device)\n",
    "        \n",
    "        result, _, _ = model(img1, img2)\n",
    "        \n",
    "        # 转换回numpy格式\n",
    "        result = result.squeeze(0).cpu().numpy()\n",
    "        result = (result * 255).astype(np.uint8)\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "初始化数据集...\n",
      "数据集初始化完成，共有 24 对图像\n",
      "开始训练模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 50/50 [01:43<00:00,  2.07s/it, avg_loss=0.0026, time=2.0s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始拼接全景图...\n",
      "Image shapes before transform - img1: (1080, 1920, 3), img2: (1080, 1920, 3)\n",
      "Image shapes before transform - img1: (1080, 1920, 3), img2: (1080, 1920, 3)\n",
      "发生错误: CUDA out of memory. Tried to allocate 15971.77 GiB. GPU 0 has a total capacity of 23.99 GiB of which 18.47 GiB is free. Of the allocated memory 1.79 GiB is allocated by PyTorch, and 2.11 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    try:\n",
    "        # 检查CUDA是否可用\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        \n",
    "        # 创建数据集和数据加载器，使用更保守的设置\n",
    "        try:\n",
    "            print(\"初始化数据集...\")\n",
    "            dataset = FramePairsDataset('temp_frames', size=(128, 128))\n",
    "            \n",
    "            # 使用单进程模式加载数据\n",
    "            train_loader = DataLoader(\n",
    "                dataset, \n",
    "                batch_size=2,\n",
    "                shuffle=True,\n",
    "                num_workers=0,  # 使用单进程\n",
    "                pin_memory=False\n",
    "                # True if torch.cuda.is_available() else False\n",
    "            )\n",
    "            print(f\"数据集初始化完成，共有 {len(dataset)} 对图像\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"创建数据加载器时出错: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "        # 创建模型\n",
    "        model = StitchingNet()\n",
    "        \n",
    "        # 训练模型\n",
    "        print(\"开始训练模型...\")\n",
    "        train_model(model, train_loader, num_epochs=50, device=device)\n",
    "        \n",
    "        # 使用训练好的模型进行拼接\n",
    "        print(\"开始拼接全景图...\")\n",
    "        result = None\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        for i in range(total_frames - 1):\n",
    "            img1 = cv2.imread(f'temp_frames/frame_{i}.jpg')\n",
    "            img2 = cv2.imread(f'temp_frames/frame_{i+1}.jpg')\n",
    "            \n",
    "            if img1 is None or img2 is None:\n",
    "                continue\n",
    "                \n",
    "            # 确保输入图像是3通道\n",
    "            if img1 is None or img2 is None:\n",
    "                print(\"Error: Failed to read images\")\n",
    "                continue\n",
    "                \n",
    "            # 转换为RGB并应用预处理\n",
    "            img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "            img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # 确保图像形状正确\n",
    "            print(f\"Image shapes before transform - img1: {img1.shape}, img2: {img2.shape}\")\n",
    "            \n",
    "            try:\n",
    "                img1 = transform(img1)\n",
    "                img2 = transform(img2)\n",
    "                \n",
    "                # 验证转换后的张量\n",
    "                assert img1.size(0) == 3, f\"Expected 3 channels, got {img1.size(0)} for img1\"\n",
    "                assert img2.size(0) == 3, f\"Expected 3 channels, got {img2.size(0)} for img2\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error during transform: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # 如果是第一帧\n",
    "            if result is None:\n",
    "                result = img1\n",
    "                continue\n",
    "            \n",
    "            # 拼接\n",
    "            result = stitch_with_model(model, result, img2, device)\n",
    "            \n",
    "            print(f\"\\r拼接进度: {i+1}/{total_frames-1}\", end=\"\", flush=True)\n",
    "            \n",
    "            # 定期保存检查点\n",
    "            if (i + 1) % 5 == 0:\n",
    "                cv2.imwrite(f'temp_frames/checkpoint_{i+1}.jpg', result)\n",
    "        \n",
    "        if result is not None:\n",
    "            print(\"\\n拼接完成\")\n",
    "            cv2.imwrite('output/panorama_dl.jpg', result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"发生错误: {str(e)}\")\n",
    "    finally:\n",
    "        # cleanup()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
